#pragma once



The Graphics Pipeline:
	The graphics pipeline contains a large number of sections that each handle one specific part of converting the vertex data to a fully rendered pixel. 


	To draw a triangle, we pass as input to the graphics pipeline, a list of 3D coordinates that should form the triangle in an array called VERTEX DATA. 
	[VERTEX DATA is a collection of vertices - a vertex is a collection of data per 3D coordinate]. 
	
	This vertex's data is represented using vertex attributes that can contain any data we'd like (simplest vertex consist of only a position (and some color value?))
	
	In order for OpenGL to know what to make of the collection of coordinates and color values, OpenGL requires a hint to what kind of render type you want to form with the
	data. Do you want it rendered as a collection of points, a collection of triangles or perhaps just a long line. Those hints are called PRIMITIVES and are given to OpenGL
	while calling any of the drawing commands. Some of these hints are GL_POINTS, GL_TRIANGLES and GL_LINE_STRIP


	Parts of the graphic pipeline:

	1:	[THE VERTEX SHADER - Transforms 3D coordinates into different 3D coordinates]
		The first part of the pipeline is the vertex shader that takes as input a single vertex. The main purpose of the vertex shader is to transform 3D coordinates into different
		3D coordinates, the vertex shader also allows us to do some basic processing on the vertex attributes. 


	2: [PRIMITIVE ASSEMBLY - Assembles into specified shape]
		The PRIMITIVE ASSEMBLY stage takes as input all the vertices (or vertex if GL_POINTS is chosen) from the vertex shader that form a primitive and assembles all the point(s)
		in the primitive shape given; in this case a triangle

	3: [GEOMETRY SHADER - Can generate other shapes by emitting new vertices]
		The output of the primitive stage is passed to the GEMOETRY SHADER, which takes as input a collection of vertices that form a primitive and has the ability to generate other
		shapes by emitting new vertices to form new primitive(s). For example, generating a second triangle out of the given shape.

	4: [THE RASTERIZATION STAGE - maps resulting primitive(s) to the corresponding pixels]
		The output of the Geometry Shader is passed to the rasterization stage where it maps the resulting primitive(s) to the corresponding pixels on the final screen, resulting
		in fragments for the fragment shader to use. Before the fragment shaders run, clipping is performed. Clipping discards all fragments that are outside your view, increasing performance.


		[A fragment in OpenGL is all the data required for OpenGL to render a single pixel.]

	5: [FRAGMENT SHADER - calculate the final color of a pixel]
		The main purpose of the fragment shader is to calculate the final color of a pixel and this is usually the stage where all the advanced OpenGL effects occur. 
		 Usually the fragment shader contains data about the 3D scene that it can use to calculate the final pixel color (like lights, shadows, color of the light and so on).

	
	6: [ALPHA TEST & BLENDING STAGE - checks if fragment is infront or behind other objects]
		After all the corresponding color values have been determined, the final object will then pass through one more stage that we call the alpha test and blending stage.
		This stage checks the corresponding depth (and stencil) value (we'll get to those later) of the fragment and uses those to check if the resulting fragment is in front 
		or behind other objects and should be discarded accordingly. The stage also checks for alpha values (alpha values define the opacity of an object) and blends the objects 
		accordingly. So even if a pixel output color is calculated in the fragment shader, the final pixel color could still be something entirely different when rendering multiple triangles.



	In modern OpenGL we are required to define at least a vertex and fragment shader of our own (there are no default vertex/fragment shaders on the GPU). 



	VERTEX INPUT
		To start drawing something we have to first give OpenGL some input vertex data. All coordinates that we specify in OpenGL are in 3D (x, y, and z coordinates)
		Normalized device coordinates is a range between 0 and 1, everything outside of this range wont show up on the screen..
		




















	TO RENDER A SINGLE TRIANGLE:
			
			Specify total of three vertices, with each having a 3D position (defined in normalized device coordinates (0.0 - 1.0)). 

			float vertices[] = {
				-0.5f, -0.5f, 0.0f,
				 0.5f, -0.5f, 0.0f,
				 0.0f,  0.5f, 0.0f
			};

			With the vertex data defined we'd like to send it as input to the first process of the graphics pipeline: the vertex shader. 
			This is done by creating memory on the GPU where we store the vertex data. We also needs to tell OpenGL how to interpret the memory
			and specify how to send the data to the graphics card. 

			The vertex shader then processes as much vertices as well tell it from its memory.

			This memory on the GPU is managed via VERTEX BUFFER OBJECTS (VBO) that can store a large number of vertices in the GPU's memory.
			The advantage of using buffer objects is that we can send large batches of data all at once to the graphics card, and keep it there if there's enough memory left,
			without having to send data one vertex at a time (sending data to the graphics card from the CPU is relatively slow).
			

			Generate a vertex buffer object using glGenBuffers function:

				unsigned int VBO;
				glGenBuffers(1, &VBO); // glGenBuffers don't return an id instead it writes the id into the assigned memory of the unsigned int.


			OpenGL has many types of buffer objects and the buffer tyoe of a vertex buffer is GL_ARRAY_BUFFER.

			We can bind (or select) the newly created buffer to the GL_ARRAY_BUFFER target with the glBindBuffer function:
				
				glBindBugger(GL_ARRAY_BUFFER, VBO);

			From that point on, any buffer calls we make (on the GL_ARRAY_BUFFER target) will be used to configure the currently bound buffer, which is VBO.

			We copy the vertex data into the selected buffers memory(?) by using glBufferData():
				
				glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW);

			glBufferData is a function specifically targeted to copy user-defined data into the currently bound buffer.

				1st argument - type of the buffer we want to copy data into: the vertex buffer object currently bound to the GL_ARRAY_BUFFER target.

				2nd argument - size of the data (in bytes) we want to pass to the buffer

				3rd argument - the actual data we want to send...

				4th argument - how the graphics card should manage the given data (can take 3 forms)

					* GL_STREAM_DRAW: the data is set only once and used by the GPU at most a few times.
					* GL_STATIC_DRAW: the data is set only once and used many times.
					* GL_DYNAMIC_DRAW: the data is changed a lot and used many times.


				We have now stored the vertex data within the memory of the graphics card as managed by a vertex buffer object named VBO.

				Next step is to create a vertex- and fragment shader that actually processes this data.
				

		VERTEX SHADER:

			The first thing we need to do is write the vertex shader in the shader language GLSL (OpenGL Shading Language) and 
			then compile this shader so we can use it in our application.
			
			 Very basic vertex shader in GLSL:
				
				#version 330 core
				layout (location = 0) in vec3 aPos;

				void main()
				{
					gl_Position = vec4(aPos.x, aPos.y, aPos.z, 1.0);
				}


			Each shader begins with a declaration of its version. Since OpenGL 3.3 and higher the version numbers of GLSL match the version of OpenGL 
			(GLSL version 420 corresponds to OpenGL version 4.2 for example).

			We also explicitly mention we're using core profile functionality.


			Next we declare all the input vertex attributes in the vertex shader with the in keyword. Right now we only care about position data so we only need a single vertex attribute. 
			GLSL has a vector datatype that contains 1 to 4 floats based on its postfix digit. Since each vertex has a 3D coordinate we create a vec3 input variable with the name aPos. 
			We also specifically set the location of the input variable via layout (location = 0) and you'll later see that why we're going to need that location.


			To set the output of the vertex shader we have to assign the position data to the predefined gl_Position variable which is a vec4 behind the scenes. At the end of the main function, 
			whatever we set gl_Position to will be used as the output of the vertex shader. Since our input is a vector of size 3 we have to cast this to a vector of size 4. We can do this by 
			inserting the vec3 values inside the constructor of vec4 and set its w component to 1.0f (we will explain why in a later chapter).

			For now we take the source code for the vertex shader and store it in a const C string: 

				const char *vertexShaderSource = "#version 330 core\n"
				 "layout (location = 0) in vec3 aPos;\n"
				 "void main()\n"
				"{\n"
				 "   gl_Position = vec4(aPos.x, aPos.y, aPos.z, 1.0);\n"
				 "}\0";



			COMPILING A SHADER:

				In order for OpenGL to use the shader, it has to dynamically compile it at run-time from its source code.
				The first thing we need to do is create a shader object, referenced by an id. We store the vertex shader as an 
				unsigned int and create the shader with glCreateShader:
				
					unsigned int vertexShader;
					vertexShader = glCreateShader(GL_VERTEX_SHADER);
					
				We provide the type of shader we want to create as an argument to glCreateShader. Since we're creating a vertex shader we pass
				in GL_VERTEX_SHADER.
				
				Next we attach the shader source code to the shader object and compile the shader:
					
					glShaderSource(vertexShader, 1, &vertexShaderSource, NULL);
					glCompileShader(vertexShader);
					
				The glShaderSource function takes the shader object to compile to as its first argument. 
				The second argument specifies how many strings we're passing as source code, which is only one.
				The third parameter is the actual source code of the vertex shader,
				we can leave the 4th parameter to NULL.

				

				You probably want to check if compilation was successful after the call to glCompileShader and if not, what errors were found so 				 you can fix those. Checking for compile-time errors is accomplished as follows:

					int  success;
					char infoLog[512];
					glGetShaderiv(vertexShader, GL_COMPILE_STATUS, &success);

				First we define an integer to indicate success and a storage container for the error messages (if any). 
				Then we check if compilation was successful with glGetShaderiv. If compilation failed, we should retrieve the error message with 				glGetShaderInfoLog and print the error message.

					if(!success)
					{
    						glGetShaderInfoLog(vertexShader, 512, NULL, infoLog);
    						std::cout << "ERROR::SHADER::VERTEX::COMPILATION_FAILED\n" << infoLog << std::endl;
					}
					
				If no errors were detected while compiling the vertex shader it is now compiled.



		FRAGMENT SHADER:
		
			The fragment shader is the second and final shader we're going to create for rendering a triangle. The fragment shader is all about 				calculating the color output of your pixels. To keep things simple the fragment shader will always output an orange-ish color.
					
			[Colors in computer graphics are represented as an array of 4 values: the red, green, blue and alpha (opacity) component, commonly 				abbreviated to RGBA. When defining a color in OpenGL or GLSL we set the strength of each component to a value between 0.0 and 1.0. If, for 			   example, we would set red to 1.0 and green to 1.0 we would get a mixture of both colors and get the color yellow. Given those 3 color 			 components we can generate over 16 million different colors!]
			
				#version 330 core
				out vec4 FragColor;

				void main()
				{
				    FragColor = vec4(1.0f, 0.5f, 0.2f, 1.0f);
				} 

			The fragment shader only requires one output variable and that is a vector of size 4 that defines the final color output that we should 			calculate ourselves. We can declare output values with the out keyword, that we here promptly named FragColor. 
			
			Next we simply assign a vec4 to the color output as an orange color with an alpha value of 1.0 (1.0 being completely opaque).

			The process for compiling a fragment shader is similar to the vertex shader, although this time we use the GL_FRAGMENT_SHADER constant as 			  the shader type:


				unsigned int fragmentShader;
				fragmentShader = glCreateShader(GL_FRAGMENT_SHADER);
				glShaderSource(fragmentShader, 1, &fragmentShaderSource, NULL);
				glCompileShader(fragmentShader);
				
				
			Both the shaders are now compiled and the only thing left to do is link both shader objects into a shader program that we can use for 				rendering. Make sure to check for compile errors here as well!


				
	Shader Program:
		A shader program object is the final linked version of multiple shaders combined. To use the recently compiled shaders we have to link them 			to a shader program object and then activate this shader program when rendering objects. The activated shader program's shaders will be used when 		we issue render calls.
		

		When linking the shaders into a program it links the outputs of each shader to the inputs of the next shader. This is also where you'll get linking 
		errors if your outputs and inputs do not match.

		
		Creating a program object is easy:
		
			unsigned int shaderProgram;
			shaderProgram = glCreateProgram();

		The glCreateProgram function creates a program and returns the ID reference to the newly created program object. Now we need to attach the 			previously compiled shaders to the program object and then link them with glLinkProgram:

			glAttachShader(shaderProgram, vertexShader);
			glAttachShader(shaderProgram, fragmentShader);
			glLinkProgram(shaderProgram);

		The code should be pretty self-explanatory, we attach the shaders to the program and link them via glLinkProgram.

		Just like shader compilation we can also check if linking a shader program failed and retrieve the corresponding log. However, instead of using
		glGetShaderiv and glGetShaderInfoLog we now use:

			glGetProgramiv(shaderProgram, GL_LINK_STATUS, &success);
			if(!success) {
    				glGetProgramInfoLog(shaderProgram, 512, NULL, infoLog);
    				...
			}
			
		The result is a program object that we can activate by calling glUseProgram with the newly created program object as its argument:

			glUseProgram(shaderProgram);
		
		Every shader and rendering call after glUseProgram will now use this program object (and thus the shaders).

		Oh yeah, and don't forget to delete the shader objects once we've linked them into the program object; we no longer need them anymore:

			glDeleteShader(vertexShader);
			glDeleteShader(fragmentShader);  

		Right now we sent the input vertex data to the GPU and instructed the GPU how it should process the vertex data within a vertex and fragment 
		shader. We're almost there, but not quite yet. OpenGL does not yet know how it should interpret the vertex data in memory and how it should connect 
		the vertex data to the vertex shader's attributes. We'll be nice and tell OpenGL how to do that.



	Linking Vertex Attributes:
	









